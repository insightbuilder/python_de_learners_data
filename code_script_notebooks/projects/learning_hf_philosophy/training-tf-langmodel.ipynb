{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from IPython.display import display, HTML\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Language Modeling:\n",
    "\n",
    "- Causal Language Modeling : Model predicts the next token in the given sentence. So the targets are **inputs shifted to right.**\n",
    "\n",
    "- Masked Language Modeling: Model has to predict some masked tokens in the given sentence, and has access to entire sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset arrow (/home/kamal/.cache/huggingface/datasets/arrow/wikitext-2-raw-v1-3f7e6bb1b926f47c/0.0.0/74f69db2c14c2860059d39860b1f400a03d11bf7fb5a8258ca38c501c878c137)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26752b26c96548d1ac4ebf3c4d66ff56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One training step will be to change this dataset with another\n",
    "# wikiset = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
    "wikiset = load_dataset(path=\"/home/kamal/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/\")\n",
    "# datasets = load_dataset(\"text\", data_files={\"train\": path_to_train.txt,\"validation\": path_to_validation.txt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' = = Construction = = \\n'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiset['train'][56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-01T23:34:11.743436Z",
     "iopub.status.busy": "2024-02-01T23:34:11.743083Z",
     "iopub.status.idle": "2024-02-01T23:34:11.750233Z",
     "shell.execute_reply": "2024-02-01T23:34:11.749335Z",
     "shell.execute_reply.started": "2024-02-01T23:34:11.743408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36718"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikiset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a function to show random elements\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset)  # dataset must have sufficient data\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset) - 1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset) - 1)\n",
    "        picks.append(pick)\n",
    "        \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>= = = Sculpture = = = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midway through the poem , there is a split between the two actions of the poem : the first attempts to identify with the nightingale and its song , and the second discusses the convergence of the past with the future while experiencing the present . This second theme is reminiscent of Keats 's view of human progression through the Mansion of Many Apartments and how man develops from experiencing and wanting only pleasure to understanding truth as a mixture of both pleasure and pain . The Elysian fields and the nightingale 's song in the first half of the poem represent the pleasurable moments that overwhelm the individual like a drug . However , the experience does not last forever , and the body is left desiring it until the narrator feels helpless without the pleasure . Instead of embracing the coming truth , the narrator clings to poetry to hide from the loss of pleasure . Poetry does not bring about the pleasure that the narrator original asks for , but it does liberate him from his desire for only pleasure . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most restorations of ceratopsians show them with erect hindlimbs but semi @-@ sprawling forelimbs , which suggest that they were not fast movers . But Paul and Christiansen ( 2000 ) argued that at least the later ceratopsians had upright forelimbs and the larger species may have been as fast as rhinos , which can run at up to 56 km or 35 miles per hour . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Many of the objects around her are also closely detailed , in particular the wooden floor and nails , the folds of the Magdalene 's dress , the costume of the figures in the exterior and the beads of Joseph 's rosary . The effect of falling light is closely studied ; Joseph 's crystal rosary beads have bright highlights , while subtle delineations of light and shade can be seen in the sideboard 's tracery and in the clasps of her book . Mary is absorbed in her reading and seemingly unaware of her surroundings . Van der Weyden has given her a quiet dignity although he is generally seen as the more emotional of the master Netherlandish painters of the era , in particular when contrasted with Jan van Eyck . \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(wikiset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to take **all the texts** in our dataset and **concatenate them** after they are tokenized. Then we will split them in examples of a certain sequence length. This way the model will receive chunks of contiguous text.\n",
    "\n",
    "The labels will be the same as the inputs, shifted to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57747ffb11594d6abb785306a71d2648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c997dad3eadc4da5afb185dee6db8134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/396k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f284bc78344c54bf0b32411ba3f260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d2f52940f447b5af8e51229829dd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/678k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c142c64566044773bcd92a62663b9c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cp = \"gpt2\"\n",
    "tokenizer_cp = \"sgugger/gpt2-like-tokenizer\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "tokeniser = AutoTokenizer.from_pretrained(tokenizer_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_text(examples):\n",
    "    return tokeniser(examples['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenised_wiki = wikiset.map(tokenise_text,\n",
    "                             batched=True,\n",
    "                             num_proc=4,\n",
    "                             remove_columns=['text'])  # will return just ids / masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised_wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4257, 2744, 258, 455, 7035, 307, 198, 4015, 218, 2078, 2098, 311, 24958, 47, 310, 263, 1282, 245, 201, 7353, 201, 225, 258, 496, 218, 951, 9516, 2143, 281, 540, 218, 196, 3115, 459, 4050, 1811, 209, 261, 2405, 2929, 5288, 8860, 16677, 296, 19000, 288, 11498, 209, 795, 3161, 258, 4489, 14881, 307, 198, 726, 218, 6785, 209, 595, 1089, 920, 201, 6785, 201, 198, 24958, 47, 3827, 198, 2405, 1657, 227, 4257, 1750, 319, 4887, 234, 363, 9899, 209, 252]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5237, 8499, 1499, 1706, 198, 6685, 196, 2923, 218, 1112, 573, 218, 1973, 263, 342, 4384, 661, 342, 1389, 1633, 3010, 209, 261, 24374, 223, 3135, 218, 342, 5688, 258, 196, 14488, 218, 4940, 1468, 201, 331, 1899, 201, 2267, 296, 196, 1304, 211, 218, 23439, 221, 230, 306, 914, 8005, 225, 20728, 6172, 18534, 296, 196, 1994, 8005, 225, 947, 7178, 370, 23651, 24756, 298, 201, 445, 331, 7936, 1927, 295, 198, 2970, 258, 239, 547, 277, 2587, 239, 225, 198, 2362, 239, 21918, 264, 8139, 424, 239, 209, 252]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[492, 11514, 2073, 1179, 311, 1617, 221, 8785, 296, 15672, 7997, 310, 440, 11954, 201, 5804, 252]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[238, 238, 4040, 3184, 238, 238, 252]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[238, 238, 12407, 238, 238, 252]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenised_wiki['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-02-02T00:25:39.594858Z",
     "iopub.status.busy": "2024-02-02T00:25:39.593899Z",
     "iopub.status.idle": "2024-02-02T00:25:39.632031Z",
     "shell.execute_reply": "2024-02-02T00:25:39.630876Z",
     "shell.execute_reply.started": "2024-02-02T00:25:39.594811Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m data_test \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m,], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m]]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# b = 0\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(data_test[b] + data_test[b+1])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# x = [sum(data_test[b], []) for b in range(3)]  # [1, 2, 5]\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "data_test = [[1, 2, 3,], [2, 5, 7], [5, 6, 8]]\n",
    "# b = 0\n",
    "# print(data_test[b] + data_test[b+1])\n",
    "\n",
    "# x = [sum(data_test[b], []) for b in range(3)]  # [1, 2, 5]\n",
    "sum(data_test[0], [])  # why this is not working??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T00:28:46.214547Z",
     "iopub.status.busy": "2024-02-02T00:28:46.214171Z",
     "iopub.status.idle": "2024-02-02T00:28:46.221809Z",
     "shell.execute_reply": "2024-02-02T00:28:46.220882Z",
     "shell.execute_reply.started": "2024-02-02T00:28:46.214520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[], [238, 8576, 9441, 2987, 238, 252], []],\n",
       " 'attention_mask': [[], [1, 1, 1, 1, 1, 1], []]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = tokenised_wiki['train'][:3]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T00:28:50.992292Z",
     "iopub.status.busy": "2024-02-02T00:28:50.991942Z",
     "iopub.status.idle": "2024-02-02T00:28:50.998670Z",
     "shell.execute_reply": "2024-02-02T00:28:50.998023Z",
     "shell.execute_reply.started": "2024-02-02T00:28:50.992268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [238, 8576, 9441, 2987, 238, 252],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data.keys() # dict_keys(['input_ids', 'attention_mask'])\n",
    "\n",
    "concat_examples = {b: sum(test_data[b], []) for b in test_data.keys()}\n",
    "concat_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T00:31:33.110373Z",
     "iopub.status.busy": "2024-02-02T00:31:33.109750Z",
     "iopub.status.idle": "2024-02-02T00:31:33.116450Z",
     "shell.execute_reply": "2024-02-02T00:31:33.115501Z",
     "shell.execute_reply.started": "2024-02-02T00:31:33.110331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[238, 8576, 9441, 2987, 238, 252]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_examples[list(test_data.keys())[0]]  # [238, 8576, 9441, 2987, 252]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T00:35:03.222716Z",
     "iopub.status.busy": "2024-02-02T00:35:03.222341Z",
     "iopub.status.idle": "2024-02-02T00:35:03.229244Z",
     "shell.execute_reply": "2024-02-02T00:35:03.228331Z",
     "shell.execute_reply.started": "2024-02-02T00:35:03.222688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('input_ids', [[], [238, 8576, 9441, 2987, 238, 252], []]), ('attention_mask', [[], [1, 1, 1, 1, 1, 1], []])])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(tokeniser.model_max_length)  # 1024 is length the model is trained on\n",
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # above will make sub_list inside input_ids and attention_masks to be extended\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # provide the total_length of input_ids\n",
    "    # we drop the remainder of the sentence, like truncating\n",
    "    tot_length = (total_length // block_size) * block_size  \n",
    "    # // will porvide only the whole number after dividing\n",
    "    # (3268 // 128) * 128 \n",
    "    # split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, tot_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # k will be keys while t will be values\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy() # inputs are duplicated as labels\n",
    "    # transformers library will apply the \"shifting to right\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = tokenised_wiki.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Ozawa. A large'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser.decode(lm_datasets['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the config and the model\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_cp)\n",
    "model = AutoModelForCausalLM.from_config(config) # this will pull the config only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510342192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_memory_footprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = AutoModelForCausalLM.from_pretrained(model_cp) # this will load the model\n",
    "del model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:06:48.071454Z",
     "iopub.status.busy": "2024-02-02T01:06:48.071050Z",
     "iopub.status.idle": "2024-02-02T01:06:48.093515Z",
     "shell.execute_reply": "2024-02-02T01:06:48.092542Z",
     "shell.execute_reply.started": "2024-02-02T01:06:48.071422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a108b485bc2f44b39b650044b1f1babb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training args\n",
    "\n",
    "t_args = TrainingArguments(\n",
    "    f\"/home/kamal/training_files/{model_cp}-wiki\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=f\"kamaljp/{model_cp}-wiki\",  # this repo must be available\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=t_args,\n",
    "    train_dataset=lm_datasets['train'],\n",
    "    eval_dataset=lm_datasets['validation']\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6750' max='6750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6750/6750 11:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.554700</td>\n",
       "      <td>6.475204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.156800</td>\n",
       "      <td>6.201700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.013200</td>\n",
       "      <td>6.114817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6750, training_loss=6.392513888888889, metrics={'train_runtime': 708.6425, 'train_samples_per_second': 76.172, 'train_steps_per_second': 9.525, 'total_flos': 3526070648832000.0, 'train_loss': 6.392513888888889, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='242' max='242' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [242/242 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 452.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:34:19.456680Z",
     "iopub.status.busy": "2024-02-02T01:34:19.455866Z",
     "iopub.status.idle": "2024-02-02T01:34:41.176061Z",
     "shell.execute_reply": "2024-02-02T01:34:41.175117Z",
     "shell.execute_reply.started": "2024-02-02T01:34:19.456646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0595d8d6b84485bfd89ccd979d6119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Kamaljp/gpt2-wiki/commit/991f8b5abc3f5bca0970a6d7f349804b7fcf9fcc', commit_message='End of training', commit_description='', oid='991f8b5abc3f5bca0970a6d7f349804b7fcf9fcc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Language Modelling\n",
    "\n",
    "Masked Language Modeling (MLM) we are going to use the same preprocessing as before for our dataset with one additional step: we will randomly mask some tokens (by replacing them by [MASK]) and the labels will be adjusted to only include the masked tokens (we don't have to predict the non-masked tokens).\n",
    "\n",
    "**The random masking is done with DataCollator at the end.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:37:29.878205Z",
     "iopub.status.busy": "2024-02-02T01:37:29.877847Z",
     "iopub.status.idle": "2024-02-02T01:37:29.968894Z",
     "shell.execute_reply": "2024-02-02T01:37:29.968184Z",
     "shell.execute_reply.started": "2024-02-02T01:37:29.878175Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_model_cp = \"bert-base-cased\"\n",
    "tokeniser_bert_cp = \"sgugger/bert-like-tokenizer\"\n",
    "\n",
    "tokeniser_bert = AutoTokenizer.from_pretrained(tokeniser_bert_cp)\n",
    "\n",
    "def tokenise_text(examples):\n",
    "    return tokeniser_bert(examples['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:37:36.212500Z",
     "iopub.status.busy": "2024-02-02T01:37:36.212120Z",
     "iopub.status.idle": "2024-02-02T01:37:36.219634Z",
     "shell.execute_reply": "2024-02-02T01:37:36.218799Z",
     "shell.execute_reply.started": "2024-02-02T01:37:36.212470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 33, 9773, 10627, 4171, 33, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenise_text(wikiset['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-02-02T01:37:42.959763Z",
     "iopub.status.busy": "2024-02-02T01:37:42.959409Z",
     "iopub.status.idle": "2024-02-02T01:37:47.978121Z",
     "shell.execute_reply": "2024-02-02T01:37:47.977104Z",
     "shell.execute_reply.started": "2024-02-02T01:37:42.959732Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1c72e6278e4e58aabbd1d11c0c691d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82533ac7ce14ecead0c0e3191bfbd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2026e9b78f456e8052862a18190c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4b0a61fede46188b747ccc87ecee13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f73b66aceb43e9a306e006a6df5a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa0d5812e7f42909ab9efc225dfd601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78333d958a684d5cb576bae5556cf5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c5668f2900448085750636cce16a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525eafbe215f418a92f83aa34d62d4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67e93c3e6f24f8aa4e8844c184d90be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9642455df02e416baf93db806bd98a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff3dee1a2554de5beeb1771db7a6ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_tokenised_ds = wikiset.map(tokenise_text,  # this has to be a function\n",
    "                               batched=True,\n",
    "                               num_proc=4,\n",
    "                               remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-02-02T01:38:15.125224Z",
     "iopub.status.busy": "2024-02-02T01:38:15.124398Z",
     "iopub.status.idle": "2024-02-02T01:38:26.313653Z",
     "shell.execute_reply": "2024-02-02T01:38:26.312617Z",
     "shell.execute_reply.started": "2024-02-02T01:38:15.125184Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9e47b6e2da43c7a8bb030d360017fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e2596279f649e98fdf6891a37fad31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521c1907c6f941e389c03a276233f3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d636ab51824e5b9e2446de277bb5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5799db77b07418ca6ce592074194408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f956d3c375be49d08733dcb14bbe326c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baac3085c7e4571beb98d8efe223346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcf3187778e4862b34ebaca837a0c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b77e21151f647bf8fe44de061d4b0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a3cc6c9f9c4bc58094fb9376d999cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719f08420230459c8671e8934c4e3dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48fa36c6f4d472fb88fdf4a56880d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_bert_ds = bert_tokenised_ds.map(group_texts,\n",
    "                                   batched=True,\n",
    "                                   batch_size=1000,\n",
    "                                   num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:38:49.675913Z",
     "iopub.status.busy": "2024-02-02T01:38:49.675536Z",
     "iopub.status.idle": "2024-02-02T01:38:52.121236Z",
     "shell.execute_reply": "2024-02-02T01:38:52.120408Z",
     "shell.execute_reply.started": "2024-02-02T01:38:49.675885Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "bert_config = AutoConfig.from_pretrained(mask_model_cp)\n",
    "model = AutoModelForMaskedLM.from_config(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:40:00.993992Z",
     "iopub.status.busy": "2024-02-02T01:40:00.993146Z",
     "iopub.status.idle": "2024-02-02T01:40:00.999013Z",
     "shell.execute_reply": "2024-02-02T01:40:00.998180Z",
     "shell.execute_reply.started": "2024-02-02T01:40:00.993959Z"
    }
   },
   "outputs": [],
   "source": [
    "# training args\n",
    "tbert_args = TrainingArguments(\n",
    "    \"test-clm\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=f\"Kamaljp/{mask_model_cp}-wiki\",\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data_collator is a function that is responsible of taking the samples and batching them in tensors. \n",
    "\n",
    "Here we want to do the random-masking. We could do it as a pre-processing step (like the tokenization) but then the tokens would always be masked the same way at each epoch. \n",
    "\n",
    "By doing this step inside the data_collator, we ensure this **random masking is done** in a new way each time we go over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:40:04.632556Z",
     "iopub.status.busy": "2024-02-02T01:40:04.632166Z",
     "iopub.status.idle": "2024-02-02T01:40:04.637290Z",
     "shell.execute_reply": "2024-02-02T01:40:04.636363Z",
     "shell.execute_reply.started": "2024-02-02T01:40:04.632528Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokeniser_bert,\n",
    "                                               mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:40:06.367882Z",
     "iopub.status.busy": "2024-02-02T01:40:06.367233Z",
     "iopub.status.idle": "2024-02-02T01:40:06.443426Z",
     "shell.execute_reply": "2024-02-02T01:40:06.442678Z",
     "shell.execute_reply.started": "2024-02-02T01:40:06.367849Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer takes the additional DataCollator\n",
    "\n",
    "trainer_bert = Trainer(\n",
    "    model=model,\n",
    "    args=tbert_args,\n",
    "    train_dataset=lm_bert_ds['train'],\n",
    "    eval_dataset=lm_bert_ds['validation'],\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:40:10.010468Z",
     "iopub.status.busy": "2024-02-02T01:40:10.010097Z",
     "iopub.status.idle": "2024-02-02T01:47:12.313765Z",
     "shell.execute_reply": "2024-02-02T01:47:12.312830Z",
     "shell.execute_reply.started": "2024-02-02T01:40:10.010440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1173' max='1173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1173/1173 07:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.213500</td>\n",
       "      <td>7.200663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1173, training_loss=7.4592584868526215, metrics={'train_runtime': 421.4989, 'train_samples_per_second': 44.51, 'train_steps_per_second': 2.783, 'total_flos': 1234474385943552.0, 'train_loss': 7.4592584868526215, 'epoch': 1.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_bert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:47:12.315532Z",
     "iopub.status.busy": "2024-02-02T01:47:12.315222Z",
     "iopub.status.idle": "2024-02-02T01:47:31.242370Z",
     "shell.execute_reply": "2024-02-02T01:47:31.241271Z",
     "shell.execute_reply.started": "2024-02-02T01:47:12.315507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 549.38\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-02T01:47:31.243876Z",
     "iopub.status.busy": "2024-02-02T01:47:31.243566Z",
     "iopub.status.idle": "2024-02-02T01:47:46.727142Z",
     "shell.execute_reply": "2024-02-02T01:47:46.726074Z",
     "shell.execute_reply.started": "2024-02-02T01:47:31.243850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5708c518c782460b80ea0652f47b0ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Kamaljp/bert-base-cased-wiki/commit/3087e13379cccef60e6ed884aee222a258c0e4c4', commit_message='End of training', commit_description='', oid='3087e13379cccef60e6ed884aee222a258c0e4c4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_bert.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
