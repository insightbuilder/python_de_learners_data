{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1cbf96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import json, openai,requests\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "import configparser\n",
    "import datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b207a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "readKey = configparser.ConfigParser()\n",
    "readKey.read_file(open('apidata.config'))\n",
    "\n",
    "openai_org = readKey['OPENAI'][\"ORG\"]\n",
    "openai_key = readKey['OPENAI']['KEY'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd1ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_response(org,key,role_player,request_content):\n",
    "    openai.organization = org\n",
    "    openai.api_key= key\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": f\"You are a {role_player}\"},\n",
    "            {\"role\": \"assistant\", \n",
    "             \"content\": f\"I have assumed the role of {role_player}\"},\n",
    "            {\"role\": \"user\", \n",
    "             \"content\": f\"\"\"If you can provide the Knowledge Graph in JSONLD for\n",
    "                         the dataset I provide, reply 'Yes I can.' \"\"\"},\n",
    "            {\"role\": \"assistant\", \n",
    "             \"content\": \"Yes I can\"},\n",
    "            {\"role\": \"user\", \n",
    "             \"content\": f\"Here is the dataset {request_content}. Provide Knowledge Graph\"}\n",
    "            ]\n",
    "        )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3656021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What role you want me to play: Dataset Summary creator\n"
     ]
    }
   ],
   "source": [
    "get_role = input(\"What role you want me to play: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b218f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset Summarizer'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a98e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "def num_tokens_from_string(string: str, \n",
    "                           encoding_name: str = 'text-davinci-003') -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c597e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the dataset sample_data.csv\n",
    "\n",
    "with open('space_titanic.csv','r') as sd:\n",
    "    data = sd.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6fc75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunks = []\n",
    "rng1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d43d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Version 1 of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2746b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before spliting data 21 and 26\n",
      "PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0017_02,Earth,False,F/6/P,55 Cancri e,14.0,False,412.0,0.0,1.0,0.0,679.0,Philda Brighttt,False\\n', '0020_01,Earth,True,E/0/S,TRAPPIST-1e,1.0,False,0.0,0.0,0.0,0.0,0.0,Almary Brantuarez,False\\n', '0020_02,Earth,True,E/0/S,55 Cancri e,49.0,False,0.0,0.0,0.0,0.0,0.0,Glendy Brantuarez,False\\n', '0020_03,Earth,True,E/0/S,55 Cancri e,29.0,False,0.0,0.0,,0.0,0.0,Mollen Mcfaddennon,False\\n', '0020_04,Earth,False,E/0/S,TRAPPIST-1e,10.0,False,0.0,0.0,0.0,0.0,0.0,Breney Jacostanley,True\\n']\n",
      "Number of tokens for the dataset 1 is 388\n",
      "before spliting data 26 and 31\n",
      "PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0020_05,Earth,True,E/0/S,PSO J318.5-22,1.0,False,,0.0,0.0,0.0,0.0,Mael Brantuarez,False\\n', '0020_06,Earth,False,E/0/S,TRAPPIST-1e,7.0,False,0.0,0.0,0.0,0.0,0.0,Terta Mcfaddennon,False\\n', '0022_01,Mars,False,D/0/P,TRAPPIST-1e,21.0,False,980.0,2.0,69.0,0.0,0.0,,False\\n', '0024_01,Europa,True,C/2/S,TRAPPIST-1e,62.0,False,0.0,0.0,,0.0,0.0,Penton Fullided,True\\n', '0025_01,Earth,False,F/6/S,TRAPPIST-1e,15.0,False,0.0,225.0,0.0,998.0,0.0,Karard Brookenson,False\\n']\n",
      "Number of tokens for the dataset 2 is 381\n"
     ]
    }
   ],
   "source": [
    "for x in list(range(1,3)):\n",
    "    rng2 = rng1 + 5\n",
    "    print(f'before spliting data {rng1} and {rng2}')\n",
    "    data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "    print(data_t)\n",
    "    prompt_made = f\"\"\"\n",
    "    dataset_{x}={data_t}\n",
    "    \n",
    "    Prompt:Refer to the [dataset_{x}] and provide the Knowledge graph that contains the \n",
    "    details of all the columns in the dataset.    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    data_chunks.append(prompt_made)\n",
    "    print(f'Number of tokens for the dataset {x} is {num_tokens_from_string(prompt_made)}')\n",
    "    rng1 = rng1 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8f138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_to_df(chunk_num,data_chunk):\n",
    "    \n",
    "    start = data_chunk.split('\\\\n')\n",
    "    \n",
    "    clean_step1 = start[0].strip(' \\n').replace('=','').replace(f'dataset_{chunk_num}','')\n",
    "\n",
    "    clean_step2 = clean_step1.split('\\n+[')\n",
    "    \n",
    "    header = clean_step2[0]\n",
    "    row1 = clean_step2[1]\n",
    "    \n",
    "    clean_row = []\n",
    "    for dat in start[1:]:\n",
    "        clean_row.append(dat.strip(\" ',\"))\n",
    "        \n",
    "    clean_row.insert(0,row1.strip(\"'\"))\n",
    "    clean_row.insert(0,header)\n",
    "    \n",
    "    clean_data_list = [data.split(',') for data in clean_row]\n",
    "    \n",
    "    chunk_df = pd.DataFrame(clean_data_list[1:-1],columns=clean_data_list[0])\n",
    "    \n",
    "    return chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecbeaa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "  RoomService FoodCourt ShoppingMall     Spa VRDeck               Name  \\\n",
       "0         0.0       0.0          0.0     0.0    0.0    Maham Ofracculy   \n",
       "1       109.0       9.0         25.0   549.0   44.0       Juanna Vines   \n",
       "2        43.0    3576.0          0.0  6715.0   49.0      Altark Susent   \n",
       "3         0.0    1283.0        371.0  3329.0  193.0       Solam Susent   \n",
       "4       303.0      70.0        151.0   565.0    2.0  Willy Santantines   \n",
       "\n",
       "  Transported  \n",
       "0       False  \n",
       "1        True  \n",
       "2       False  \n",
       "3       False  \n",
       "4        True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_to_df(1,data_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c521e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_output = extract_response(org=openai_org, key=openai_key, \n",
    "                 role_player=get_role, request_content=data_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a50e8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the JSON-LD Knowledge Graph for the dataset you provided:\\n\\n```\\n{\\n  \"@context\": {\\n    \"schema\": \"http://schema.org/\",\\n    \"passenger\": \"schema:Person\",\\n    \"identifier\": \"schema:identifier\",\\n    \"homePlanet\": \"schema:homeLocation\",\\n    \"cryoSleep\": \"schema:isRelatedTo\",\\n    \"cabin\": \"schema:occupationalCategory\",\\n    \"destination\": \"schema:destination\",\\n    \"age\": \"schema:age\",\\n    \"vip\": \"schema:isVIP\",\\n    \"roomService\": \"schema:hasRoomService\",\\n    \"foodCourt\": \"schema:hasFoodCourt\",\\n    \"shoppingMall\": \"schema:hasShoppingMall\",\\n    \"spa\": \"schema:hasSpa\",\\n    \"vrDeck\": \"schema:hasVRDeck\",\\n    \"name\": \"schema:name\",\\n    \"transported\": \"schema:isTransported\"\\n  },\\n  \"@type\": \"passenger\",\\n  \"identifier\": \"PassengerId\",\\n  \"homePlanet\": \"HomePlanet\",\\n  \"cryoSleep\": \"CryoSleep\",\\n  \"cabin\": \"Cabin\",\\n  \"destination\": \"Destination\",\\n  \"age\": \"Age\",\\n  \"vip\": \"VIP\",\\n  \"roomService\": \"RoomService\",\\n  \"foodCourt\": \"FoodCourt\",\\n  \"shoppingMall\": \"ShoppingMall\",\\n  \"spa\": \"Spa\",\\n  \"vrDeck\": \"VRDeck\",\\n  \"name\": \"Name\",\\n  \"transported\": \"Transported\"\\n}\\n```\\n\\nThis JSON-LD Knowledge Graph defines the schema for the dataset you provided, with `PassengerId`, `HomePlanet`, `CryoSleep`, `Cabin`, `Destination`, `Age`, `VIP`, `RoomService`, `FoodCourt`, `ShoppingMall`, `Spa`, `VRDeck`, `Name`, and `Transported` as the primary attributes.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301283d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Version 2 of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef079cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before spliting data 31 and 36\n",
      "Number of tokens for the dataset is 397\n",
      "\n",
      "dataset_2=PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0026_01,Europa,False,C/0/P,55 Cancri e,34.0,False,22.0,6073.0,0.0,1438.0,328.0,Anyoni Unconary,False\\n', '0028_01,Mars,False,F/8/P,TRAPPIST-1e,43.0,False,1125.0,0.0,136.0,48.0,0.0,Ceros Mare,False\\n', '0030_01,Earth,False,G/4/S,TRAPPIST-1e,32.0,False,0.0,850.0,81.0,437.0,453.0,Ginia Morsentley,False\\n', '0031_01,Mars,False,F/9/P,TRAPPIST-1e,47.0,False,214.0,0.0,1411.0,0.0,1229.0,Coobix Datie,True\\n', '0031_02,Mars,False,F/9/P,TRAPPIST-1e,2.0,False,0.0,0.0,0.0,0.0,0.0,Cinets Datie,True\\n']\n",
      "\n",
      "Prompt:Refer to the [dataset] and summarize it as a Knowledge graph that contains the \n",
      "details of all the columns in the dataset, and your inference of the dataset    \n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rng2 = rng1 + 5\n",
    "print(f'before spliting data {rng1} and {rng2}')\n",
    "data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "#print(data_t)\n",
    "prompt_made = f\"\"\"\n",
    "dataset_{x}={data_t}\n",
    "\n",
    "Prompt:Refer to the [dataset] and summarize it as a Knowledge graph that contains the \n",
    "details of all the columns in the dataset, and your inference of the dataset    \n",
    "Answer:\n",
    "\"\"\"\n",
    "print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "print(prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c977b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_output_2 = extract_response(org=openai_org,key=openai_key,\n",
    "                                role_player=get_role, \n",
    "                                  request_content=prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc14ab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s the Knowledge Graph in JSON-LD format for the given dataset:\\n\\n```\\n{\\n  \"@context\": {\\n    \"schema\": \"http://schema.org/\"\\n  },\\n  \"@type\": \"schema:Dataset\",\\n  \"schema:name\": \"Passenger Information\",\\n  \"schema:description\": \"A dataset containing information about passengers travelling to TRAPPIST-1e from various planets.\",\\n  \"schema:creator\": \"Your Name\",\\n  \"schema:variableMeasured\": {\\n    \"@type\": \"schema:Property\",\\n    \"schema:name\": \"Passenger Attributes\",\\n    \"schema:description\": \"The attributes of each passenger in the dataset.\",\\n    \"schema:variableMeasured\": [\"HomePlanet\", \"CryoSleep\", \"Cabin\", \"Destination\", \"Age\", \"VIP\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Name\", \"Transported\"]\\n  },\\n  \"schema:includedInDataCatalog\": {\\n    \"@type\": \"schema:DataCatalog\",\\n    \"schema:name\": \"Some Dataset Repository\",\\n    \"schema:url\": \"http://example.com\"\\n  }\\n}\\n```\\n\\nFrom the given dataset, we can infer that the dataset contains information about passengers who are travelling to a planet called TRAPPIST-1e from different planets. The dataset contains attributes such as HomePlanet (planet from where the passenger originates), CryoSleep (if the passenger was in cryogenic sleep during travel), Cabin (cabin in which the passenger travelled), Destination (planet to which the passenger is travelling), Age (age of the passenger), VIP (if the passenger is a VIP), RoomService (room service availed by the passenger), FoodCourt (food court availed by the passenger), ShoppingMall (shopping mall availed by the passenger), Spa (spa facilities availed by the passenger), VRDeck (virtual reality deck used by the passenger), Name (name of the passenger), Transported (if the passenger was transported or not).'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15b13800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 3 of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4878fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary(org,key,role_player,request_content):\n",
    "    openai.organization = org\n",
    "    openai.api_key= key\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": f\"You are a {role_player}\"},\n",
    "            {\"role\": \"assistant\", \n",
    "             \"content\": f\"I have assumed the role of {role_player}\"},\n",
    "            {\"role\": \"user\", \n",
    "             \"content\": f\"Here is the dataset {request_content}.\"}\n",
    "            ]\n",
    "        )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2301dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before spliting data 1 and 6\n",
      "Number of tokens for the dataset is 377\n",
      "\n",
      "dataset=PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0001_01,Europa,False,B/0/P,TRAPPIST-1e,39.0,False,0.0,0.0,0.0,0.0,0.0,Maham Ofracculy,False\\n', '0002_01,Earth,False,F/0/S,TRAPPIST-1e,24.0,False,109.0,9.0,25.0,549.0,44.0,Juanna Vines,True\\n', '0003_01,Europa,False,A/0/S,TRAPPIST-1e,58.0,True,43.0,3576.0,0.0,6715.0,49.0,Altark Susent,False\\n', '0003_02,Europa,False,A/0/S,TRAPPIST-1e,33.0,False,0.0,1283.0,371.0,3329.0,193.0,Solam Susent,False\\n', '0004_01,Earth,False,F/1/S,TRAPPIST-1e,16.0,False,303.0,70.0,151.0,565.0,2.0,Willy Santantines,True\\n']\n",
      "\n",
      "Prompt:Refer to the [dataset] and list 50 statistical, factual and inferential questions    \n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rng2 = rng1 + 5\n",
    "print(f'before spliting data {rng1} and {rng2}')\n",
    "data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "#print(data_t)\n",
    "prompt_made = f\"\"\"\n",
    "dataset={data_t}\n",
    "\n",
    "Prompt:Refer to the [dataset] and list 50 statistical, factual and inferential questions    \n",
    "Answer:\n",
    "\"\"\"\n",
    "print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "print(prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f775193",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_3 = extract_summary(org=openai_org, key=openai_key, \n",
    "                 role_player=get_role, request_content=prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89787919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. How many entries are in the dataset?\\n2. What is the minimum age of the passengers?\\n3. What is the maximum age of the passengers?\\n4. What is the average age of the passengers?\\n5. What is the median age of the passengers?\\n6. What is the mode of the age distribution of the passengers?\\n7. How many different home planets are represented in the dataset?\\n8. What is the most common home planet?\\n9. How many passengers are in cryosleep?\\n10. What percentage of the passengers are in cryosleep?\\n11. What is the distribution of cabins among the passengers?\\n12. What is the most common cabin type?\\n13. What is the most common destination?\\n14. How many passengers are VIPs?\\n15. What percentage of the passengers are VIPs?\\n16. What is the average room service rating of the passengers?\\n17. What is the median room service rating of the passengers?\\n18. What is the mode of the room service ratings of the passengers?\\n19. What is the average food court rating of the passengers?\\n20. What is the median food court rating of the passengers?\\n21. What is the mode of the food court ratings of the passengers?\\n22. What is the average shopping mall rating of the passengers?\\n23. What is the median shopping mall rating of the passengers?\\n24. What is the mode of the shopping mall ratings of the passengers?\\n25. What is the average spa rating of the passengers?\\n26. What is the median spa rating of the passengers?\\n27. What is the mode of the spa ratings of the passengers?\\n28. What is the average VR deck rating of the passengers?\\n29. What is the median VR deck rating of the passengers?\\n30. What is the mode of the VR deck ratings of the passengers?\\n31. How many passengers have a name that starts with the letter 'M'?\\n32. What is the most common starting letter for passenger names?\\n33. How many passengers were transported on TRAPPIST-1e?\\n34. What percentage of the passengers were transported on TRAPPIST-1e?\\n35. What is the average age of passengers transported on TRAPPIST-1e?\\n36. What is the median age of passengers transported on TRAPPIST-1e?\\n37. What is the mode of the age distribution of passengers transported on TRAPPIST-1e?\\n38. How many passengers were transported using the transport named 'Maham Ofracculy'?\\n39. What percentage of the passengers were transported using the transport named 'Maham Ofracculy'?\\n40. How many passengers were transported using the transport named 'Juanna Vines'?\\n41. What percentage of the passengers were transported using the transport named 'Juanna Vines'?\\n42. How many passengers were transported using the transport named 'Altark Susent'?\\n43. What percentage of the passengers were transported using the transport named 'Altark Susent'?\\n44. How many passengers were transported using the transport named 'Solam Susent'?\\n45. What percentage of the passengers were transported using the transport named 'Solam Susent'?\\n46. How many passengers were transported using the transport named 'Willy Santantines'?\\n47. What percentage of the passengers were transported using the transport named 'Willy Santantines'?\\n48. How many passengers experienced VIP amenities during their trip?\\n49. What percentage of the passengers experienced VIP amenities during their trip?\\n50. How many passengers did not experience any of the amenities on the trip?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d01206a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "questions_list = inference_3.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d287d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7. How many different home planets are represented in the dataset?',\n",
       " '8. What is the most common home planet?',\n",
       " '9. How many passengers are in cryosleep?',\n",
       " '10. What percentage of the passengers are in cryosleep?',\n",
       " '11. What is the distribution of cabins among the passengers?',\n",
       " '12. What is the most common cabin type?',\n",
       " '13. What is the most common destination?',\n",
       " '14. How many passengers are VIPs?',\n",
       " '15. What percentage of the passengers are VIPs?',\n",
       " '16. What is the average room service rating of the passengers?',\n",
       " '17. What is the median room service rating of the passengers?',\n",
       " '18. What is the mode of the room service ratings of the passengers?',\n",
       " '19. What is the average food court rating of the passengers?',\n",
       " '20. What is the median food court rating of the passengers?',\n",
       " '21. What is the mode of the food court ratings of the passengers?',\n",
       " '22. What is the average shopping mall rating of the passengers?',\n",
       " '23. What is the median shopping mall rating of the passengers?',\n",
       " '24. What is the mode of the shopping mall ratings of the passengers?',\n",
       " '25. What is the average spa rating of the passengers?']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_list[6:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bbe885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_string = ''\n",
    "for string in questions_list[6:15]:\n",
    "    quest_string = quest_string + string.split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53e30606",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Follow up prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a3df977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before spliting data 41 and 46\n",
      "Number of tokens for the dataset is 468\n",
      "\n",
      "dataset=PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0039_01,Earth,True,G/1/P,55 Cancri e,30.0,False,0.0,0.0,,0.0,0.0,Jorgie Batthewitt,False\\n', '0041_01,Earth,True,G/2/P,TRAPPIST-1e,17.0,False,0.0,0.0,0.0,0.0,0.0,Margia Moodsey,True\\n', '0043_01,Europa,False,B/3/P,TRAPPIST-1e,45.0,False,0.0,164.0,45.0,2511.0,855.0,Ankalik Cylistrand,False\\n', '0044_01,Earth,True,G/3/P,TRAPPIST-1e,55.0,False,0.0,0.0,0.0,0.0,0.0,Jodye Coopelandez,False\\n', '0044_02,Earth,True,G/3/P,55 Cancri e,4.0,False,0.0,0.0,0.0,0.0,0.0,Kayne Coopelandez,True\\n']\n",
      "\n",
      "Prompt:Refer to the [dataset] and answer succinctly to the following questions. \n",
      " How many different home planets are represented in the dataset? What is the most common home planet? How many passengers are in cryosleep? What percentage of the passengers are in cryosleep? What is the distribution of cabins among the passengers? What is the most common cabin type? What is the most common destination? How many passengers are VIPs? What percentage of the passengers are VIPs?\n",
      "At the end print COMPLETED INFERENCE\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rng2 = rng1 + 5\n",
    "print(f'before spliting data {rng1} and {rng2}')\n",
    "data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "#print(data_t)\n",
    "prompt_made = f\"\"\"\n",
    "dataset={data_t}\n",
    "\n",
    "Prompt:Refer to the [dataset] and answer succinctly to the following questions. \n",
    "{quest_string}\n",
    "At the end print COMPLETED INFERENCE\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "print(prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53a96ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "designed_summary =  extract_summary(org=openai_org, key=openai_key, \n",
    "                 role_player=get_role, request_content=prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76458b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- There are at least 3 different home planets represented in the dataset.\\n- The most common home planet is Earth, as it appears at least twice in the dataset.\\n- There are at least 2 passengers in cryosleep.\\n- It is not possible to calculate the percentage of passengers that are in cryosleep as the total number of passengers is not provided in the dataset.\\n- The cabins distribution is partially represented in the dataset, with at least 4 different cabin types: G/1/P, G/2/P, B/3/P and G/3/P.\\n- The most common cabin type is G/3/P, as it appears at least twice in the dataset.\\n- TRAPPIST-1e is the most common destination, as it appears at least 3 times in the dataset.\\n- There are no VIP passengers in the dataset.\\n- It is not possible to calculate the percentage of VIP passengers as the total number of passengers is not provided in the dataset.\\n\\nCOMPLETED INFERENCE'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designed_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85cdf78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(designed_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f69b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if gpt can make such inferences directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "adaa4966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before spliting data 41 and 46\n",
      "Number of tokens for the dataset is 377\n",
      "\n",
      "dataset=PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0039_01,Earth,True,G/1/P,55 Cancri e,30.0,False,0.0,0.0,,0.0,0.0,Jorgie Batthewitt,False\\n', '0041_01,Earth,True,G/2/P,TRAPPIST-1e,17.0,False,0.0,0.0,0.0,0.0,0.0,Margia Moodsey,True\\n', '0043_01,Europa,False,B/3/P,TRAPPIST-1e,45.0,False,0.0,164.0,45.0,2511.0,855.0,Ankalik Cylistrand,False\\n', '0044_01,Earth,True,G/3/P,TRAPPIST-1e,55.0,False,0.0,0.0,0.0,0.0,0.0,Jodye Coopelandez,False\\n', '0044_02,Earth,True,G/3/P,55 Cancri e,4.0,False,0.0,0.0,0.0,0.0,0.0,Kayne Coopelandez,True\\n']\n",
      "\n",
      "Prompt:Refer to the [dataset] and succinctly list 10 statistical, factual and inferences    \n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rng2 = rng1 + 5\n",
    "print(f'before spliting data {rng1} and {rng2}')\n",
    "data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "#print(data_t)\n",
    "prompt_made = f\"\"\"\n",
    "dataset={data_t}\n",
    "\n",
    "Prompt:Refer to the [dataset] and succinctly list 10 statistical, factual and inferences    \n",
    "Answer:\n",
    "\"\"\"\n",
    "print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "print(prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce03aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_possiblity =  extract_summary(org=openai_org, key=openai_key, \n",
    "                 role_player=get_role, request_content=prompt_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5ab37e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The dataset contains information on individuals who have undergone cryosleep.\\n2. Home planet, cabin, destination, and age are recorded for each individual.\\n3. There are VIP individuals who have access to room service, food court, shopping mall, spa, and VR deck.\\n4. Some individuals have been transported to their destination while some have not.\\n5. The dataset contains information on individuals from multiple planets, including Earth and Europa.\\n6. The age of individuals ranges from 4 to 55 years old.\\n7. There are individuals who were transported to both TRAPPIST-1e and 55 Cancri e.\\n8. The dataset contains at least 5 entries.\\n9. There are individuals with similar last names (Coopelandez).\\n10. There is missing data for some amenities, as some individuals have NaN values for shopping mall or spa access.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_possiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fe0c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It infers in its own method. But the earlier 50 question guided it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39568101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before spliting data 1 and 11\n",
      "Number of tokens for the dataset is 775\n",
      "before spliting data 11 and 21\n",
      "Number of tokens for the dataset is 758\n",
      "before spliting data 21 and 31\n",
      "Number of tokens for the dataset is 759\n",
      "before spliting data 31 and 41\n",
      "Number of tokens for the dataset is 769\n"
     ]
    }
   ],
   "source": [
    "inference_requests = []\n",
    "rng1 = 1\n",
    "for x in list(range(1,5)):\n",
    "    rng2 = rng1 + 10\n",
    "    print(f'before spliting data {rng1} and {rng2}')\n",
    "    data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "    #print(data_t)\n",
    "    prompt_made = f\"\"\"\n",
    "    dataset={data_t}\n",
    "\n",
    "    Prompt:Refer to the [dataset] and in 300 words answer the following questions.\n",
    "    Do not print the questions. \n",
    "    {quest_string}\n",
    "    At the end print COMPLETED INFERENCE\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "    inference_requests.append(prompt_made)\n",
    "    rng1 = rng1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "645d0e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens for the dataset is 678\n",
      "Number of tokens for the dataset is 661\n",
      "Number of tokens for the dataset is 662\n",
      "Number of tokens for the dataset is 672\n"
     ]
    }
   ],
   "source": [
    "prompt_questions = []\n",
    "rng1 = 1\n",
    "for x in list(range(1,5)):\n",
    "    rng2 = rng1 + 10\n",
    "    data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "    prompt_made = f\"\"\"\n",
    "    dataset={data_t}\n",
    "\n",
    "    Prompt:Refer to the [dataset] and make the phy-beta-gamma version of inferences.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "    prompt_questions.append(prompt_made)\n",
    "    rng1 = rng1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0273187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens for the dataset is 663\n",
      "Number of tokens for the dataset is 663\n",
      "Number of tokens for the dataset is 666\n",
      "Number of tokens for the dataset is 679\n"
     ]
    }
   ],
   "source": [
    "prompt_to_pbg = []\n",
    "rng1 = 41\n",
    "for x in list(range(1,5)):\n",
    "    rng2 = rng1 + 10\n",
    "    data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "    prompt_made = f\"\"\"\n",
    "    dataset={data_t}\n",
    "\n",
    "    Prompt:Refer to the [dataset] and make the phy-beta-gamma version of inferences.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "    prompt_to_pbg.append(prompt_made)\n",
    "    rng1 = rng1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb5a001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    dataset=PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0039_01,Earth,True,G/1/P,55 Cancri e,30.0,False,0.0,0.0,,0.0,0.0,Jorgie Batthewitt,False\\n', '0041_01,Earth,True,G/2/P,TRAPPIST-1e,17.0,False,0.0,0.0,0.0,0.0,0.0,Margia Moodsey,True\\n', '0043_01,Europa,False,B/3/P,TRAPPIST-1e,45.0,False,0.0,164.0,45.0,2511.0,855.0,Ankalik Cylistrand,False\\n', '0044_01,Earth,True,G/3/P,TRAPPIST-1e,55.0,False,0.0,0.0,0.0,0.0,0.0,Jodye Coopelandez,False\\n', '0044_02,Earth,True,G/3/P,55 Cancri e,4.0,False,0.0,0.0,0.0,0.0,0.0,Kayne Coopelandez,True\\n', '0044_03,Earth,True,G/3/P,PSO J318.5-22,21.0,False,0.0,0.0,0.0,0.0,0.0,Cassa Coopelandez,True\\n', '0045_01,Mars,False,F/10/P,TRAPPIST-1e,21.0,False,970.0,0.0,180.0,0.0,64.0,Zelowl Chmad,False\\n', '0045_02,Mars,True,F/10/P,,19.0,False,0.0,0.0,0.0,0.0,0.0,Mass Chmad,True\\n', '0050_01,Earth,False,E/1/S,55 Cancri e,35.0,False,790.0,0.0,0.0,,0.0,Sony Lancis,False\\n', '0051_01,Earth,False,E/2/S,TRAPPIST-1e,56.0,False,0.0,112.0,0.0,1379.0,127.0,Vivia Johnshines,False\\n']\n",
      "\n",
      "    Prompt:Refer to the [dataset] and make the phy-beta-gamma version of inferences.\n",
      "\n",
      "    Answer:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt_to_pbg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "572ae097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inference_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "efb9f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,inf in enumerate(inference_requests):\n",
    "    comp = extract_summary(org=openai_org, key=openai_key, \n",
    "                 role_player=get_role, request_content=inf)\n",
    "    prompt_dict = {'prompt':prompt_questions[ind],\n",
    "                  'completion':comp}\n",
    "    with open('inferences_prompt_04.jsonl','a+') as inje:\n",
    "        json.dump(prompt_dict,fp=inje)\n",
    "        inje.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58fe1173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(prompt_dict['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "605b3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_upload(filename, purpose='fine-tune'):\n",
    "    resp = openai.File.create(purpose=purpose,file=open(file=filename,\n",
    "                                                        mode='rb'))\n",
    "    return resp[\"id\"]\n",
    "\n",
    "def finetune_model(fileId, suffix,model='davinci',api_key=openai_key):\n",
    "    header = {'Content-Type':'application/json',\n",
    "              'Authorization':f'Bearer {api_key}'}\n",
    "    payload = {'training_file':fileId,'model':model,'suffix':suffix}\n",
    "    resp = requests.request(method='POST',\n",
    "                            url='https://api.openai.com/v1/fine-tunes',\n",
    "                           headers=header,\n",
    "                           json=payload,timeout=40)\n",
    "    model_id = resps.json()['id']\n",
    "    return(model_id)\n",
    "    \n",
    "def finetune_get(ftId,api_key=openai_key):\n",
    "    header = {'Content-Type':'application/json',\n",
    "              'Authorization':f'Bearer {api_key}'}\n",
    "    resp = requests.request(method='GET',\n",
    "                url=f'https://api.openai.com/v1/fine-tunes/{ftId}',\n",
    "                           headers=header,timeout=40)\n",
    "    reply_matter = resp.json()['events']\n",
    "    return(reply_matter)\n",
    "    \n",
    "def finetune_event(ftId,api_key=openai_key):\n",
    "    header = {'Content-Type':'application/json',\n",
    "              'Authorization':f'Bearer {api_key}'}\n",
    "    resp = requests.request(method='GET',\n",
    "                url=f'https://api.openai.com/v1/fine-tunes/{ftId}/events',\n",
    "                           headers=header,timeout=40)\n",
    "    print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ccf22a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_completion(org, key,prompt,prompt_part,\n",
    "                    engine='text-davinci-003',temp=0.1,\n",
    "                   top_p=1.0,tokens=200,freq_pen=0.0,\n",
    "                   pres_pen=0.0,stop=['asdfasdf','asdfasdf'],\n",
    "                   filename='inferences_prompt_06.jsonl'):\n",
    "    \"\"\"The function will take the prompt and the prompt parts to \n",
    "    begin the data collection. Once the data collection is completed, \n",
    "    the prompt part will be used for fine tuning. The prompt used will \n",
    "    be discarded\"\"\"\n",
    "    openai.api_key = key\n",
    "    openai.organization = org\n",
    "    max_retry=5\n",
    "    retry = 0\n",
    "    prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "            model=engine,\n",
    "            prompt=prompt,\n",
    "            temperature=temp,\n",
    "            max_tokens=tokens,\n",
    "            top_p=top_p,\n",
    "            frequency_penalty=freq_pen,\n",
    "            presence_penalty=pres_pen,\n",
    "            stop=stop)\n",
    "            \n",
    "            text = response['choices'][0]['text'].strip()\n",
    "            dict_reply = {'prompt':prompt_part,'completion':text}\n",
    "            with open(filename,'a+') as taker:\n",
    "                json.dump(dict_reply,fp=taker)\n",
    "                taker.write('\\n')\n",
    "            \n",
    "            return dict_reply\n",
    "        except Exception as e:\n",
    "            retry += 1\n",
    "            if retry > max_retry:\n",
    "                return f'GPT errored out {e}'\n",
    "            sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35112c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-eJPMsRVDjOFoLMOEditavKoj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file-eJPMsRVDjOFoLMOEditavKoj'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_upload(filename='inferences_prompt_04.jsonl',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2acd5c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'fine-tune', 'id': 'ft-k5AtqXOKUOouYeUsEyUsfyMO', 'hyperparams': {'n_epochs': 4, 'batch_size': None, 'prompt_loss_weight': 0.01, 'learning_rate_multiplier': None}, 'organization_id': 'org-QWWIpNe4Z3KsRVI0YR6lhyJW', 'model': 'davinci', 'training_files': [{'object': 'file', 'id': 'file-eJPMsRVDjOFoLMOEditavKoj', 'purpose': 'fine-tune', 'filename': 'file', 'bytes': 9690, 'created_at': 1678494835, 'status': 'processed', 'status_details': None}], 'validation_files': [], 'result_files': [], 'created_at': 1678494855, 'updated_at': 1678494855, 'status': 'pending', 'fine_tuned_model': None, 'events': [{'object': 'fine-tune-event', 'level': 'info', 'message': 'Created fine-tune: ft-k5AtqXOKUOouYeUsEyUsfyMO', 'created_at': 1678494855}]}\n"
     ]
    }
   ],
   "source": [
    "finetune_model(fileId='file-eJPMsRVDjOFoLMOEditavKoj',\n",
    "               suffix='phy-beta-gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4a682f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'object': 'fine-tune-event', 'level': 'info', 'message': 'Created fine-tune: ft-k5AtqXOKUOouYeUsEyUsfyMO', 'created_at': 1678494855}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Fine-tune costs $0.47', 'created_at': 1678495110}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Fine-tune enqueued. Queue number: 0', 'created_at': 1678495111}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Fine-tune started', 'created_at': 1678495113}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Completed epoch 1/4', 'created_at': 1678495229}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Completed epoch 2/4', 'created_at': 1678495233}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Completed epoch 3/4', 'created_at': 1678495237}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Completed epoch 4/4', 'created_at': 1678495241}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Uploaded model: davinci:ft-kamal:phy-beta-gamma-2023-03-11-00-41-26', 'created_at': 1678495287}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Uploaded result file: file-94atrb3JBxRw7DvnUWLpMN3v', 'created_at': 1678495288}, {'object': 'fine-tune-event', 'level': 'info', 'message': 'Fine-tune succeeded', 'created_at': 1678495288}]\n"
     ]
    }
   ],
   "source": [
    "finetune_get(ftId='ft-k5AtqXOKUOouYeUsEyUsfyMO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c0b9b725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before spliting data 1 and 11\n",
      "Number of tokens for the dataset is 785\n",
      "before spliting data 11 and 21\n",
      "Number of tokens for the dataset is 768\n",
      "before spliting data 21 and 31\n",
      "Number of tokens for the dataset is 769\n",
      "before spliting data 31 and 41\n",
      "Number of tokens for the dataset is 779\n",
      "before spliting data 41 and 51\n",
      "Number of tokens for the dataset is 770\n",
      "before spliting data 51 and 61\n",
      "Number of tokens for the dataset is 770\n",
      "before spliting data 61 and 71\n",
      "Number of tokens for the dataset is 773\n",
      "before spliting data 71 and 81\n",
      "Number of tokens for the dataset is 786\n",
      "before spliting data 81 and 91\n",
      "Number of tokens for the dataset is 775\n",
      "before spliting data 91 and 101\n",
      "Number of tokens for the dataset is 771\n",
      "before spliting data 101 and 111\n",
      "Number of tokens for the dataset is 778\n",
      "before spliting data 111 and 121\n",
      "Number of tokens for the dataset is 765\n",
      "before spliting data 121 and 131\n",
      "Number of tokens for the dataset is 767\n",
      "before spliting data 131 and 141\n",
      "Number of tokens for the dataset is 764\n",
      "before spliting data 141 and 151\n",
      "Number of tokens for the dataset is 784\n",
      "before spliting data 151 and 161\n",
      "Number of tokens for the dataset is 788\n",
      "before spliting data 161 and 171\n",
      "Number of tokens for the dataset is 773\n",
      "before spliting data 171 and 181\n",
      "Number of tokens for the dataset is 781\n",
      "before spliting data 181 and 191\n",
      "Number of tokens for the dataset is 772\n",
      "before spliting data 191 and 201\n",
      "Number of tokens for the dataset is 772\n",
      "before spliting data 201 and 211\n",
      "Number of tokens for the dataset is 782\n",
      "before spliting data 211 and 221\n",
      "Number of tokens for the dataset is 773\n",
      "before spliting data 221 and 231\n",
      "Number of tokens for the dataset is 760\n",
      "before spliting data 231 and 241\n",
      "Number of tokens for the dataset is 777\n",
      "before spliting data 241 and 251\n",
      "Number of tokens for the dataset is 778\n",
      "before spliting data 251 and 261\n",
      "Number of tokens for the dataset is 779\n",
      "before spliting data 261 and 271\n",
      "Number of tokens for the dataset is 782\n",
      "before spliting data 271 and 281\n",
      "Number of tokens for the dataset is 782\n",
      "before spliting data 281 and 291\n",
      "Number of tokens for the dataset is 762\n",
      "before spliting data 291 and 301\n",
      "Number of tokens for the dataset is 771\n",
      "before spliting data 301 and 311\n",
      "Number of tokens for the dataset is 771\n",
      "before spliting data 311 and 321\n",
      "Number of tokens for the dataset is 766\n",
      "before spliting data 321 and 331\n",
      "Number of tokens for the dataset is 778\n",
      "before spliting data 331 and 341\n",
      "Number of tokens for the dataset is 793\n",
      "before spliting data 341 and 351\n",
      "Number of tokens for the dataset is 775\n",
      "before spliting data 351 and 361\n",
      "Number of tokens for the dataset is 789\n",
      "before spliting data 361 and 371\n",
      "Number of tokens for the dataset is 767\n",
      "before spliting data 371 and 381\n",
      "Number of tokens for the dataset is 789\n",
      "before spliting data 381 and 391\n",
      "Number of tokens for the dataset is 787\n",
      "before spliting data 391 and 401\n",
      "Number of tokens for the dataset is 783\n",
      "before spliting data 401 and 411\n",
      "Number of tokens for the dataset is 782\n",
      "before spliting data 411 and 421\n",
      "Number of tokens for the dataset is 781\n",
      "before spliting data 421 and 431\n",
      "Number of tokens for the dataset is 788\n",
      "before spliting data 431 and 441\n",
      "Number of tokens for the dataset is 759\n",
      "before spliting data 441 and 451\n",
      "Number of tokens for the dataset is 773\n",
      "before spliting data 451 and 461\n",
      "Number of tokens for the dataset is 768\n",
      "before spliting data 461 and 471\n",
      "Number of tokens for the dataset is 773\n",
      "before spliting data 471 and 481\n",
      "Number of tokens for the dataset is 796\n",
      "before spliting data 481 and 491\n",
      "Number of tokens for the dataset is 749\n"
     ]
    }
   ],
   "source": [
    "inference_requests = []\n",
    "rng1 = 1\n",
    "for x in list(range(1,50)):\n",
    "    rng2 = rng1 + 10\n",
    "    print(f'before spliting data {rng1} and {rng2}')\n",
    "    data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "    #print(data_t)\n",
    "    prompt_made = f\"\"\"\n",
    "    dataset={data_t}\n",
    "\n",
    "    Prompt:Refer to the [dataset] and in 300 words answer the following questions. Remember that these queries are\n",
    "    insight_builder queries.Do not print the queries. \n",
    "    {quest_string}\n",
    "    At the end print COMPLETED INFERENCE\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made)}')\n",
    "    inference_requests.append(prompt_made)\n",
    "    rng1 = rng1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16cddf5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens for the dataset is 683\n",
      "Number of tokens for the dataset is 666\n",
      "Number of tokens for the dataset is 667\n",
      "Number of tokens for the dataset is 677\n",
      "Number of tokens for the dataset is 668\n",
      "Number of tokens for the dataset is 668\n",
      "Number of tokens for the dataset is 671\n",
      "Number of tokens for the dataset is 684\n",
      "Number of tokens for the dataset is 673\n",
      "Number of tokens for the dataset is 669\n",
      "Number of tokens for the dataset is 676\n",
      "Number of tokens for the dataset is 663\n",
      "Number of tokens for the dataset is 665\n",
      "Number of tokens for the dataset is 662\n",
      "Number of tokens for the dataset is 682\n",
      "Number of tokens for the dataset is 686\n",
      "Number of tokens for the dataset is 671\n",
      "Number of tokens for the dataset is 679\n",
      "Number of tokens for the dataset is 670\n",
      "Number of tokens for the dataset is 670\n",
      "Number of tokens for the dataset is 680\n",
      "Number of tokens for the dataset is 671\n",
      "Number of tokens for the dataset is 658\n",
      "Number of tokens for the dataset is 675\n",
      "Number of tokens for the dataset is 676\n",
      "Number of tokens for the dataset is 677\n",
      "Number of tokens for the dataset is 680\n",
      "Number of tokens for the dataset is 680\n",
      "Number of tokens for the dataset is 660\n",
      "Number of tokens for the dataset is 669\n",
      "Number of tokens for the dataset is 669\n",
      "Number of tokens for the dataset is 664\n",
      "Number of tokens for the dataset is 676\n",
      "Number of tokens for the dataset is 691\n",
      "Number of tokens for the dataset is 673\n",
      "Number of tokens for the dataset is 687\n",
      "Number of tokens for the dataset is 665\n",
      "Number of tokens for the dataset is 687\n",
      "Number of tokens for the dataset is 685\n",
      "Number of tokens for the dataset is 681\n",
      "Number of tokens for the dataset is 680\n",
      "Number of tokens for the dataset is 679\n",
      "Number of tokens for the dataset is 686\n",
      "Number of tokens for the dataset is 657\n",
      "Number of tokens for the dataset is 671\n",
      "Number of tokens for the dataset is 666\n",
      "Number of tokens for the dataset is 671\n",
      "Number of tokens for the dataset is 694\n",
      "Number of tokens for the dataset is 647\n"
     ]
    }
   ],
   "source": [
    "prompt_questions = []\n",
    "rng1 = 1\n",
    "for x in list(range(1,50)):\n",
    "    rng2 = rng1 + 10\n",
    "    data_t = f'{data[0]}+{data[rng1:rng2]}'\n",
    "    prompt_made = f\"\"\"\n",
    "    dataset={data_t}\n",
    "\n",
    "    Prompt:Refer to the [dataset] and make inferences based on insight_builder queries.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    print(f'Number of tokens for the dataset is {num_tokens_from_string(prompt_made,encoding_name=\"davinci\")}')\n",
    "    prompt_questions.append(prompt_made)\n",
    "    rng1 = rng1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0c67f497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    dataset=PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\n",
      "+['0517_01,Earth,False,F/109/P,TRAPPIST-1e,,False,1445.0,0.0,1.0,2.0,73.0,Jandy Kimons,False\\n', '0518_01,,True,F/92/S,TRAPPIST-1e,35.0,False,0.0,0.0,0.0,0.0,0.0,Soyos Parta,True\\n', '0519_01,Earth,True,G/77/S,TRAPPIST-1e,,False,0.0,0.0,0.0,0.0,0.0,Ryany Farleyatton,True\\n', '0520_01,Earth,False,G/78/S,TRAPPIST-1e,55.0,False,62.0,,0.0,0.0,,Bel Mcguirez,False\\n', '0521_01,Earth,False,E/32/S,TRAPPIST-1e,23.0,False,39.0,263.0,0.0,0.0,,Hery Hornettoney,True\\n', '0522_01,Earth,False,E/33/P,TRAPPIST-1e,42.0,False,0.0,0.0,750.0,0.0,156.0,Glenry Parklaney,False\\n', '0523_01,Earth,False,E/33/S,TRAPPIST-1e,35.0,False,553.0,213.0,1733.0,0.0,6.0,Helley Joyneidez,True\\n', '0525_01,Earth,True,,TRAPPIST-1e,47.0,False,0.0,0.0,0.0,0.0,0.0,Wenise Mirezavis,True\\n', '0527_01,Mars,False,F/93/S,55 Cancri e,,False,1172.0,11.0,3.0,0.0,4.0,Supce Stit,False\\n', '0527_02,Mars,True,F/93/S,TRAPPIST-1e,34.0,False,0.0,0.0,0.0,0.0,0.0,Llat Stit,True\\n']\n",
      "\n",
      "    Prompt:Refer to the [dataset] and in 300 words answer the following questions. Remember that these queries are\n",
      "    insight_builder queries.Do not print the queries. \n",
      "     How many different home planets are represented in the dataset? What is the most common home planet? How many passengers are in cryosleep? What percentage of the passengers are in cryosleep? What is the distribution of cabins among the passengers? What is the most common cabin type? What is the most common destination? How many passengers are VIPs? What percentage of the passengers are VIPs?\n",
      "    At the end print COMPLETED INFERENCE\n",
      "\n",
      "    Answer:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(inference_requests[48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "371ff25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"\\n    dataset=PassengerId,HomePlanet,CryoSleep,Cabin,Destination,Age,VIP,RoomService,FoodCourt,ShoppingMall,Spa,VRDeck,Name,Transported\\n+['0017_02,Earth,False,F/6/P,55 Cancri e,14.0,False,412.0,0.0,1.0,0.0,679.0,Philda Brighttt,False\\\\n', '0020_01,Earth,True,E/0/S,TRAPPIST-1e,1.0,False,0.0,0.0,0.0,0.0,0.0,Almary Brantuarez,False\\\\n', '0020_02,Earth,True,E/0/S,55 Cancri e,49.0,False,0.0,0.0,0.0,0.0,0.0,Glendy Brantuarez,False\\\\n', '0020_03,Earth,True,E/0/S,55 Cancri e,29.0,False,0.0,0.0,,0.0,0.0,Mollen Mcfaddennon,False\\\\n', '0020_04,Earth,False,E/0/S,TRAPPIST-1e,10.0,False,0.0,0.0,0.0,0.0,0.0,Breney Jacostanley,True\\\\n', '0020_05,Earth,True,E/0/S,PSO J318.5-22,1.0,False,,0.0,0.0,0.0,0.0,Mael Brantuarez,False\\\\n', '0020_06,Earth,False,E/0/S,TRAPPIST-1e,7.0,False,0.0,0.0,0.0,0.0,0.0,Terta Mcfaddennon,False\\\\n', '0022_01,Mars,False,D/0/P,TRAPPIST-1e,21.0,False,980.0,2.0,69.0,0.0,0.0,,False\\\\n', '0024_01,Europa,True,C/2/S,TRAPPIST-1e,62.0,False,0.0,0.0,,0.0,0.0,Penton Fullided,True\\\\n', '0025_01,Earth,False,F/6/S,TRAPPIST-1e,15.0,False,0.0,225.0,0.0,998.0,0.0,Karard Brookenson,False\\\\n']\\n\\n    Prompt:Refer to the [dataset] and make inferences based on insight_builder queries.\\n\\n    Answer:\\n    \",\n",
       " 'completion': 'There are two different home planets represented in the dataset: Earth and Mars. Earth is the most common home planet, with nine passengers out of the total eleven passengers. Two passengers are in cryosleep, which is 18.18% of the total passengers. The distribution of cabins among the passengers is F/6/P, E/0/S, D/0/P, and C/2/S. The most common cabin type is E/0/S, with four passengers. The most common destination is TRAPPIST-1e, with five passengers. Only one passenger is a VIP, which is 9.09% of the total passengers. \\n    \\n    COMPLETED INFERENCE'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt3_completion(org=openai_org,key=openai_key,\n",
    "                           filename='inferences_prompt_temp.jsonl',prompt=inference_requests[2],\n",
    "                          prompt_part=prompt_questions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3f47d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,inf in enumerate(inference_requests):\n",
    "    comp = gpt3_completion(org=openai_org,key=openai_key,\n",
    "                           filename='inferences_prompt_08.jsonl',prompt=inf,\n",
    "                          prompt_part=prompt_questions[ind])\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "87b29a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-ElAaw9TYVGi9Rer1oyvEHsI9'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_upload(filename='inferences_prompt_08.jsonl',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "285fba49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinetune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile-ElAaw9TYVGi9Rer1oyvEHsI9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdavinci_inferences\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[158], line 14\u001b[0m, in \u001b[0;36mfinetune_model\u001b[0;34m(fileId, suffix, model, api_key)\u001b[0m\n\u001b[1;32m      9\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_file\u001b[39m\u001b[38;5;124m'\u001b[39m:fileId,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m:model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffix\u001b[39m\u001b[38;5;124m'\u001b[39m:suffix}\n\u001b[1;32m     10\u001b[0m resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1/fine-tunes\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m                        headers\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m     13\u001b[0m                        json\u001b[38;5;241m=\u001b[39mpayload,timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[43mresps\u001b[49m\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(model_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resps' is not defined"
     ]
    }
   ],
   "source": [
    "finetune_model(fileId='file-ElAaw9TYVGi9Rer1oyvEHsI9',\n",
    "               suffix='davinci_inferences')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
