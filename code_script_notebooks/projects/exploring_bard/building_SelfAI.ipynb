{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Notebook contains \n",
        "\n",
        "The prompts that are taken from the sample usecases inside vertex ai for study"
      ],
      "metadata": {
        "id": "oStOJ3grcSJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform transformers sentence-transformers faiss-cpu langchain > /dev/null"
      ],
      "metadata": {
        "id": "Ycq4yn2FrrZX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep aiplatform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb27tjk7lp_6",
        "outputId": "f1ff5f45-c774-48f6-fcb4-b282ce045369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google-cloud-aiplatform==1.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "oCC7y2Dm7lee"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel"
      ],
      "metadata": {
        "id": "pbIzm2oXrq61"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_large_language_model_sample(\n",
        "    project_id: str,\n",
        "    model_name: str,\n",
        "    temperature: float,\n",
        "    max_decode_steps: int,\n",
        "    top_p: float,\n",
        "    top_k: int,\n",
        "    content: str,\n",
        "    location: str = \"us-central1\",\n",
        "    tuned_model_name: str = \"\",\n",
        "    ) :\n",
        "    \"\"\"Predict using a Large Language Model.\"\"\"\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "    model = TextGenerationModel.from_pretrained(model_name)\n",
        "    if tuned_model_name:\n",
        "      model = model.get_tuned_model(tuned_model_name)\n",
        "\n",
        "    response = model.predict(\n",
        "        content,\n",
        "        temperature=temperature,\n",
        "        max_output_tokens=max_decode_steps,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,)\n",
        "\n",
        "    print(f\"Response from Model: {response.text}\")\n",
        "\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "cmQPdwc57yV7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr2KIxDOcI9h"
      },
      "outputs": [],
      "source": [
        "# Support rep chat summarization\n",
        "\n",
        "prompt_birth = '''Name of the character Michael karthik who is affectionately called as mike by his schoolmates.\n",
        "Create a 300 word back story revolving around his child hood. \n",
        "Speaks about his family, his life in suburban city in a developed country.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply_birth = predict_large_language_model_sample(\"generativeaitrial\", \n",
        "                                    \"text-bison@001\", \n",
        "                                    0.2, \n",
        "                                    256, \n",
        "                                    0.8, \n",
        "                                    40,\n",
        "                                    prompt_birth)"
      ],
      "metadata": {
        "id": "FzXGwYwM7_y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('michaelKarthik.txt',mode='w',encoding='utf-8') as mic:\n",
        "  mic.write(reply_birth)"
      ],
      "metadata": {
        "id": "Wg03g7yE6DDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Linkedin Articles\n",
        "\n",
        "prompt_posts ='''Write 10 linkedin posts that would be written Michael.  \n",
        "Below is the information about michael\n",
        "Michael spend hours playing video games and learning about how computers. \n",
        "He realized eventually that computer was his passion.\n",
        "After high school, Michael went to college to study computer science. \n",
        "He graduated with honors and got a job as a software engineer'''"
      ],
      "metadata": {
        "id": "LAElDzMOfmI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply_posts = predict_large_language_model_sample(\"generativeaitrial\", \n",
        "                                    \"text-bison@001\", \n",
        "                                    0.2, \n",
        "                                    1024, \n",
        "                                    0.8, \n",
        "                                    40,\n",
        "                                    prompt_posts)"
      ],
      "metadata": {
        "id": "MUjJ2N6dsbQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('michaelKarthik.txt',\n",
        "          mode='a+',\n",
        "          encoding='utf-8') as mic:\n",
        "  mic.write(reply_posts)"
      ],
      "metadata": {
        "id": "uUzi8z-sfmFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_medium ='''Write 10 medium articles that would be written Michael.  \n",
        "Below is the information about michael\n",
        "Michael spend hours working on Machine learning and algorithms. \n",
        "He realized python and assembly language his major study area.\n",
        "Michael is a computer science graduate working as a software engineer'''"
      ],
      "metadata": {
        "id": "r-YEZfHBshfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply_articles = predict_large_language_model_sample(\"generativeaitrial\", \n",
        "                                    \"text-bison@001\", \n",
        "                                    0.2, \n",
        "                                    1024, \n",
        "                                    0.8, \n",
        "                                    40,\n",
        "                                    prompt_medium)"
      ],
      "metadata": {
        "id": "vsgdllIAfmDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('michaelKarthik.txt',\n",
        "          mode='a+',\n",
        "          encoding='utf-8') as mic:\n",
        "  mic.write('\\n')\n",
        "  mic.write(reply_articles)"
      ],
      "metadata": {
        "id": "9TyRMQy_soPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_tweets = \"\"\"Michael likes to hang out with friends and \n",
        "engages with his friends and followers on Twitter. Michael is smart \n",
        "savvy about algorithms and likes to joke about AI on twitter. \n",
        "Based on above information write 25 tweets written by Michael\"\"\""
      ],
      "metadata": {
        "id": "IM3V5iepfmAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply_tweets = predict_large_language_model_sample(\"generativeaitrial\", \n",
        "                                    \"text-bison@001\", \n",
        "                                    0.2, \n",
        "                                    1024, \n",
        "                                    0.8, \n",
        "                                    40,\n",
        "                                    prompt_tweets)"
      ],
      "metadata": {
        "id": "uukXWaKTs0Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('michaelKarthik.txt',\n",
        "          mode='a+',\n",
        "          encoding='utf-8') as mic:\n",
        "  mic.write('\\n')\n",
        "  mic.write(reply_tweets)"
      ],
      "metadata": {
        "id": "lhm5i2Kxfl-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_prefs = \"\"\"Michael lived in city and enjoys hanging out with \n",
        "friends, dating females and chilling out at beach. His preferences \n",
        "are sophisticated and mature. Write 200 words about his prefernces on \n",
        "cars, colors, food, favorite places, hobbies, art, music, movies \n",
        "and clothing\"\"\""
      ],
      "metadata": {
        "id": "b-r92O8yEWoe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply_prefs = predict_large_language_model_sample(\"generativeaitrial\", \n",
        "                                    \"text-bison@001\", \n",
        "                                    0.2, \n",
        "                                    1024, \n",
        "                                    0.8, \n",
        "                                    40,\n",
        "                                    prompt_prefs)"
      ],
      "metadata": {
        "id": "0z6NAfuVFJXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the data ready next we can start the vector stores embedding"
      ],
      "metadata": {
        "id": "sdyYldbcGyIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('michaelKarthik.txt',\n",
        "          mode='a+',\n",
        "          encoding='utf-8') as mic:\n",
        "  mic.write('\\n')\n",
        "  mic.write(reply_prefs)"
      ],
      "metadata": {
        "id": "1ymUSApHFjM_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/michaelKarthik.txt') as f:\n",
        "  mike = f.read()"
      ],
      "metadata": {
        "id": "QTbjEcoPqo_2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import NLTKTextSplitter\n",
        "nltk_splitter = NLTKTextSplitter(chunk_size=500)"
      ],
      "metadata": {
        "id": "TRUfSEINm4wZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df763286-90b6-42bb-a7af-c96cd7d855bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.utilities.powerbi:Could not import azure.core python package.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beC8c17_n03g",
        "outputId": "73c94e5e-84df-49cc-b1e5-80d279043a7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_docs = nltk_splitter.split_text(mike)\n",
        "\n",
        "print(len(nltk_docs))\n",
        "nltk_docs[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMtzrhgMm4sF",
        "outputId": "e87e092e-6062-461c-9915-0bda75aa3386"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Michael Karthik was born in a suburban city in a developed country to Indian parents.\\n\\nHis father was a software engineer and his mother was a stay-at-home mom.\\n\\nMichael had one older sister and one younger brother.\\n\\nMichael's childhood was happy and carefree.\\n\\nHe loved playing with his siblings and friends.\\n\\nHe was also a good student and enjoyed learning new things.\\n\\nMichael's parents were always supportive of him and encouraged him to follow his dreams.\",\n",
              " \"He loved playing with his siblings and friends.\\n\\nHe was also a good student and enjoyed learning new things.\\n\\nMichael's parents were always supportive of him and encouraged him to follow his dreams.\\n\\nWhen Michael was in high school, he started to get interested in computers.\\n\\nHe would spend hours playing video games and learning about how computers worked.\\n\\nMichael's parents were initially worried about his obsession with computers, but they eventually realized that it was his passion.\",\n",
              " \"Michael's parents were initially worried about his obsession with computers, but they eventually realized that it was his passion.\\n\\nAfter high school, Michael went to college to study computer science.\\n\\nHe graduated with honors and got a job as a software engineer at a large tech company.\\n\\nMichael quickly rose through the ranks and became a successful engineer.\\n\\nMichael is now married with two children.\\n\\nHe lives in a nice house in the suburbs and drives a luxury car.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings \n",
        "\n",
        "embed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "lFS23aMHsm3c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "db = FAISS.from_texts(nltk_docs, embed)"
      ],
      "metadata": {
        "id": "l9kSh-DTpchB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How was Michael childhood\"\n",
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "CF2V5rmHtA3H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_convPrompt(question):\n",
        "  \"\"\"Gets the supporting documents from Mikes data\"\"\"\n",
        "  docs = db.similarity_search(question)\n",
        "  text = ''\n",
        "  for loc in docs:\n",
        "    text = text + loc.page_content\n",
        "\n",
        "  prompt = f\"\"\" {question} \n",
        "  Reply to the question by thinking step by step. \n",
        "  You can use the following context that is collected from Michael's past data. \n",
        "  {text}\n",
        "  You can share your thoughts before completing the reply\n",
        "  End the reply with 10 word question related to discussion\"\"\"\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "bI_mmptstAsx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"Today was interesting, and enjoyable. Hows was your day Michael?\"\n",
        "\n",
        "query1_prompt = build_convPrompt(query1)\n",
        "\n",
        "print(query1_prompt)"
      ],
      "metadata": {
        "id": "Vn-4mIP2tAmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797b3b8b-31da-40d9-be2c-2fbba78baeab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Today was interesting, and enjoyable. Hows was your day Michael? \n",
            "  Reply to the question by thinking step by step. \n",
            "  You can use the following context that is collected from Michael's past data. \n",
            "  Michael quickly rose through the ranks and became a successful engineer.\n",
            "\n",
            "Michael is now married with two children.\n",
            "\n",
            "He lives in a nice house in the suburbs and drives a luxury car.\n",
            "\n",
            "Michael is grateful for his successful career and happy family life.\n",
            "\n",
            "He knows that he is lucky to have such a great life.\n",
            "\n",
            "Michael's story is an inspiration to others.\n",
            "\n",
            "It1.\n",
            "\n",
            "**Michael's first LinkedIn post**\n",
            "\n",
            "I'm excited to announce that I've accepted a new position as a software engineer at Google!Thank you to everyone who has supported me along the way.\n",
            "\n",
            "I couldn't have done it without you!\n",
            "\n",
            "2.\n",
            "\n",
            "**Michael's post about his first day at work**\n",
            "\n",
            "My first day at Google was an amazing experience!\n",
            "\n",
            "I was welcomed by a warm and friendly team, and I was immediately given the opportunity to contribute to a project that I'm passionate about.\n",
            "\n",
            "I'm learning so much every day, and I'm excited to see what the future holds.Michael's story is an inspiration to others.\n",
            "\n",
            "It1.\n",
            "\n",
            "**Michael's first LinkedIn post**\n",
            "\n",
            "I'm excited to announce that I've accepted a new position as a software engineer at Google!\n",
            "\n",
            "I'm so grateful for this opportunity, and I can't wait to get started.\n",
            "\n",
            "I've always been passionate about computers, and I'm thrilled to be able to work on cutting-edge technology.\n",
            "\n",
            "I'm also looking forward to collaborating with some of the brightest minds in the industry.He lives in the city and enjoys spending time with his friends, dating women, and relaxing on the beach.\n",
            "\n",
            "He has a taste for expensive cars, classic clothing, and fine art.\n",
            "\n",
            "He enjoys listening to jazz and classical music, and he prefers to watch movies that are thought-provoking and challenging.\n",
            "\n",
            "Here are some of Michael's preferences in more detail:\n",
            "\n",
            "* Cars: Michael prefers luxury cars, such as Mercedes-Benz, BMW, and Audi.\n",
            "\n",
            "He enjoys the comfort, performance, and style of these cars.\n",
            "  You can share your thoughts before completing the reply\n",
            "  End the reply with 10 word question related to discussion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query1_reply = predict_large_language_model_sample(\"generativeaitrial\", \n",
        "                                    \"text-bison@001\", \n",
        "                                    0.2, \n",
        "                                    1024, \n",
        "                                    0.8, \n",
        "                                    40,\n",
        "                                    query1_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mybFLM5Iqzp",
        "outputId": "b2b2ddb8-4f8f-4549-f1fc-243cb8b70f15"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from Model: My day was good, thanks for asking. I had a productive day at work and I got to spend some time with my family in the evening. How was your day?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query1_reply"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w-5uKhB_I2p5",
        "outputId": "19419431-cce8-4d36-9b25-eeef99bf43a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"My day was great! I got to work on a new project that I'm really excited about. How was your day?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"My day was bit hectic and had a rough time with my boss\"\n",
        "\n",
        "query2_prompt = build_convPrompt(query2)\n",
        "\n",
        "print(query2_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD30egOkI6rI",
        "outputId": "b3a11342-7e44-4313-b221-0d634c81e0ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " My day was bit hectic and had a rough time with my boss \n",
            "  Reply to the question by thinking step by step. \n",
            "  You can use the following context that is collected from Michael's past data. \n",
            "  Thank you to everyone who has supported me along the way.\n",
            "\n",
            "I couldn't have done it without you!\n",
            "\n",
            "2.\n",
            "\n",
            "**Michael's post about his first day at work**\n",
            "\n",
            "My first day at Google was an amazing experience!\n",
            "\n",
            "I was welcomed by a warm and friendly team, and I was immediately given the opportunity to contribute to a project that I'm passionate about.\n",
            "\n",
            "I'm learning so much every day, and I'm excited to see what the future holds.9.\n",
            "\n",
            "**Michael's post about a promotion he received**\n",
            "\n",
            "I'm excited to announce that I've been promoted to Senior Software Engineer!\n",
            "\n",
            "I'm grateful for the opportunity to continue growing my career at Google, and I'm looking forward to taking on new challenges.\n",
            "\n",
            "I'm also grateful for the support of my colleagues and managers.\n",
            "\n",
            "I couldn't have achieved this without them.\n",
            "\n",
            "10.\n",
            "\n",
            "**Michael's post about his new company**\n",
            "\n",
            "I'm excited to announce that I've started my own company!I'm really grateful for this opportunity, and I'm looking forward to working on some cutting-edge technology.\n",
            "\n",
            "I'm also looking forward to collaborating with some of the brightest minds in the industry.\n",
            "\n",
            "I'm confident that I'll be able to make a significant contribution to the company, and I'm excited to see what the future holds.\n",
            "\n",
            "9.\n",
            "\n",
            "**Michael's post about a promotion he received**\n",
            "\n",
            "I'm excited to announce that I've been promoted to Senior Software Engineer!I'm also looking forward to collaborating with some of the brightest minds in the industry.\n",
            "\n",
            "I'm confident that I'll be able to make a significant contribution to Google, and I'm excited to see what the future holds.\n",
            "\n",
            "Thank you to everyone who has supported me along the way.\n",
            "\n",
            "I couldn't have done it without you!\n",
            "\n",
            "2.\n",
            "\n",
            "**Michael's post about his first day at work**\n",
            "\n",
            "My first day at Google was an amazing experience!\n",
            "  You can share your thoughts before completing the reply\n",
            "  End the reply with 10 word question related to discussion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2_reply = predict_large_language_model_sample(\"generativeaitrial\", \n",
        "                                    \"text-bison@001\", \n",
        "                                    0.2, \n",
        "                                    1024, \n",
        "                                    0.8, \n",
        "                                    40,\n",
        "                                    query2_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv8ODFdHJOTc",
        "outputId": "02647c70-b72c-4e1a-9c51-d73e6657d8d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from Model: Sorry to hear that. Hope your day gets better. Do you want to talk about it?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(query2_reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lhJtTZGJO8e",
        "outputId": "31f4c42a-ada9-49cd-990d-bb7db77ac689"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you think about the new project you're working on?\n"
          ]
        }
      ]
    }
  ]
}