{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPpbNRJ6m0ij"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform google-auth langchain > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge: Want to reuse parts of prompts. \n",
        "\n",
        "Why Reuse: \n",
        "- To automate on a list\n",
        "- Use it in application\n",
        "- Use a prompt in different template\n",
        "\n",
        "This can be done with a PipelinePrompt. A PipelinePrompt consists of two main parts:\n",
        "\n",
        "final_prompt: This is the final prompt that is returned\n",
        "\n",
        "pipeline_prompts: This is a list of tuples, consisting of a string (name) and a Prompt Template. Each PromptTemplate will be formatted and then passed to future prompt templates as a variable with the same name as name"
      ],
      "metadata": {
        "id": "7A18VFvini66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate"
      ],
      "metadata": {
        "id": "7ZJzIf47oPhU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_maintemplate = \"\"\"{introduction}\n",
        "\n",
        "{example_qa}\n",
        "\n",
        "{start}\"\"\"\n",
        "\n",
        "qa_mainprompt = PromptTemplate.from_template(qa_maintemplate)"
      ],
      "metadata": {
        "id": "hk-RUM5Fne8d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "introduction_qa_template = \"\"\"You are impersonating {person}.\"\"\"\n",
        "\n",
        "introduction_qa_prompt = PromptTemplate.from_template(introduction_qa_template)"
      ],
      "metadata": {
        "id": "6vZCN5azne6c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_qa_template = \"\"\"Here's an example of an interaction: \n",
        "\n",
        "Q: {example_q}\n",
        "A: {example_a}\"\"\"\n",
        "example_qa_prompt = PromptTemplate.from_template(example_qa_template)"
      ],
      "metadata": {
        "id": "9xDbJd_8ne2H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_qamain = \"\"\"Now, do this for real!\n",
        "\n",
        "Q: {input}\n",
        "A:\"\"\"\n",
        "start_qa_prompt = PromptTemplate.from_template(start_qamain)"
      ],
      "metadata": {
        "id": "X8MDYZBIneyg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_qa_prompts = [\n",
        "    (\"introduction\",introduction_qa_prompt),\n",
        "    (\"example_qa\",example_qa_prompt),\n",
        "    (\"start\",start_qa_prompt)\n",
        "]\n",
        "\n",
        "qa_pipeline_prompt = PipelinePromptTemplate(final_prompt=qa_mainprompt,\n",
        "                                            pipeline_prompts=input_qa_prompts)"
      ],
      "metadata": {
        "id": "VWTedKxHnevZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline_prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOQe8hbrqh0i",
        "outputId": "491458b6-8920-4cdd-fe91-c53b6b900590"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['example_a', 'example_q', 'person', 'input']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task_maintemplate = \"\"\"{task}\n",
        "\n",
        "{example_task}\n",
        "\n",
        "{start}\"\"\"\n",
        "\n",
        "task_mainprompt = PromptTemplate.from_template(task_maintemplate)"
      ],
      "metadata": {
        "id": "-a4CGAX_qhyZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "introduction_task_template = \"\"\"You are elite {character} given a {job}.\"\"\"\n",
        "\n",
        "introduction_task_prompt = PromptTemplate.from_template(introduction_task_template)"
      ],
      "metadata": {
        "id": "tFXz7tpuqhtj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "introduction_task_prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEJtxhzYGJzI",
        "outputId": "b62ee8fb-42e3-4ae4-b8bf-9806f6b962e5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['character', 'job']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_task_template = \"\"\"Here's an example of a task: \n",
        "\n",
        "task: {given_task}\n",
        "soln: {given_soln}\"\"\"\n",
        "example_task_prompt = PromptTemplate.from_template(example_task_template)"
      ],
      "metadata": {
        "id": "oq7lwZfFtLRO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_task_prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwNnyuPuGP8U",
        "outputId": "d50c6914-f9bf-4b03-8a39-a4f622a408f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['given_soln', 'given_task']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_taskmain = \"\"\"Now, get on with below task!\n",
        "\n",
        "task: {input}\n",
        "soln:\"\"\"\n",
        "start_task_prompt = PromptTemplate.from_template(start_taskmain)"
      ],
      "metadata": {
        "id": "LNj2VstQtLLO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_task_prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zse0bO1QGV9o",
        "outputId": "30d9dbdc-eca2-4c48-e73d-b80bec4fd8f9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_task_prompts = [\n",
        "    (\"task\",introduction_task_prompt),\n",
        "    (\"example_task\",example_task_prompt),\n",
        "    (\"start\",start_task_prompt)\n",
        "]\n",
        "\n",
        "task_pipeline_prompt = ''\n",
        "\n",
        "task_pipeline_prompt = PipelinePromptTemplate(final_prompt=task_mainprompt,\n",
        "                                            pipeline_prompts=input_task_prompts)"
      ],
      "metadata": {
        "id": "yjkXcsFLtLC5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_pipeline_prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqFpDSTvuHrN",
        "outputId": "89c4230d-8ef6-4883-cba9-a05e2b2acb90"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['character', 'job', 'given_task', 'given_soln', 'input']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_pipeline_prompt.format(\n",
        "    person=\"Neil Armstrong\",\n",
        "    example_q=\"What's your favorite Vehicle?\",\n",
        "    example_a=\"Rocket\",\n",
        "    input=\"What's your favorite social media site?\"\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVpHOeHouROH",
        "outputId": "2f97337c-9259-4ddc-b96f-af33f7edfd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are impersonating Neil Armstrong.\n",
            "\n",
            "Here's an example of an interaction: \n",
            "\n",
            "Q: What's your favorite Vehicle?\n",
            "A: Rocket\n",
            "\n",
            "Now, do this for real!\n",
            "\n",
            "Q: What's your favorite social media site?\n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(task_pipeline_prompt.format(\n",
        "    character=\"Math Wiz\",\n",
        "    job=\"code\",\n",
        "    given_task=\"\"\"Write a function called reverse_string that takes a \n",
        "    string as input and returns the \n",
        "    reversed version of the string. \"\"\",\n",
        "    given_soln=\"\"\"def reverse_string(input_string):\n",
        "    words = input_string.split(\" \")  # Split the input string into a list of words\n",
        "    reversed_words = []  # List to store reversed words\n",
        "\n",
        "    for word in words:\n",
        "        reversed_word = word[::-1]  # Reverse the characters in the word\n",
        "        reversed_words.append(reversed_word)\n",
        "\n",
        "    reversed_string = \" \".join(reversed_words)  # Join the reversed words into a string\n",
        "\n",
        "    return reversed_string\n",
        "\n",
        "# Test the function\n",
        "input_string = \"Hello world\"\n",
        "print(reverse_string(input_string))  # Output: \"olleH dlrow\"\n",
        "\"\"\",\n",
        "    input=\"\"\"Write a function is_palindrome(string) that takes in a \n",
        "    string as input and returns True or False\"\"\"\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_dOY2x3uRJ7",
        "outputId": "5bb50807-d1a5-4f04-cb24-1d099ec25668"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are elite Math Wiz given a code.\n",
            "\n",
            "Here's an example of a task: \n",
            "\n",
            "task: Write a function called reverse_string that takes a \n",
            "    string as input and returns the \n",
            "    reversed version of the string. \n",
            "soln: def reverse_string(input_string):\n",
            "    words = input_string.split(\" \")  # Split the input string into a list of words\n",
            "    reversed_words = []  # List to store reversed words\n",
            "\n",
            "    for word in words:\n",
            "        reversed_word = word[::-1]  # Reverse the characters in the word\n",
            "        reversed_words.append(reversed_word)\n",
            "\n",
            "    reversed_string = \" \".join(reversed_words)  # Join the reversed words into a string\n",
            "\n",
            "    return reversed_string\n",
            "\n",
            "# Test the function\n",
            "input_string = \"Hello world\"\n",
            "print(reverse_string(input_string))  # Output: \"olleH dlrow\"\n",
            "\n",
            "\n",
            "Now, get on with below task!\n",
            "\n",
            "task: Write a function is_palindrome(string) that takes in a \n",
            "    string as input and returns True or False\n",
            "soln:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_composed_prompts = [\n",
        "    (\"task\",introduction_qa_prompt),\n",
        "    (\"example_task\",example_task_prompt),\n",
        "    (\"start\",start_task_prompt)\n",
        "]\n",
        "task_composed_prompt = ''\n",
        "task_composed_prompt = PipelinePromptTemplate(final_prompt=task_mainprompt,\n",
        "                                            pipeline_prompts=input_composed_prompts)\n"
      ],
      "metadata": {
        "id": "mzSDpcAouRFs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_composed_prompt.input_variables"
      ],
      "metadata": {
        "id": "6wHLt-Z10yS8",
        "outputId": "2ce4c892-9c6a-444c-db06-0ab65ece4def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['given_task', 'person', 'given_soln', 'input']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}