{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6Wag04Hk5jA",
        "outputId": "4f0ed015-f6ee-4398-87f8-0fcae2610817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain chromadb google-cloud-aiplatform google-auth google-search-results > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='/content/generativeaitrial-trialLC.json'"
      ],
      "metadata": {
        "id": "veeMOmfFn3W8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "nEJ7I3hFlqX0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "llm = VertexAI(temperature=0)\n",
        "summary_chain = load_summarize_chain(llm, \n",
        "                                     chain_type=\"map_reduce\")"
      ],
      "metadata": {
        "id": "NUEmaHJ1lqP4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import AnalyzeDocumentChain\n",
        "\n",
        "summarize_document_chain = AnalyzeDocumentChain(combine_docs_chain=summary_chain)"
      ],
      "metadata": {
        "id": "eeXjZhwnlqKS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_output(documents):\n",
        "  summarize_document_chain.run()"
      ],
      "metadata": {
        "id": "cvXyvXk0lqHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip lc_documentdb.zip"
      ],
      "metadata": {
        "id": "saRKisZYpD5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "embeddings = VertexAIEmbeddings()\n",
        "\n",
        "persist_directory = '/content/content/lc_documentdb'\n",
        "\n",
        "vectordb = Chroma(persist_directory=persist_directory, \n",
        "                  embedding_function=embeddings)\n",
        "\n",
        "db_retriever = vectordb.as_retriever()\n",
        "\n",
        "\n",
        "langchain_qa = RetrievalQA.from_chain_type(llm=VertexAI(), \n",
        "                                 chain_type=\"stuff\", \n",
        "                                 retriever=db_retriever)"
      ],
      "metadata": {
        "id": "kbEayoqgoe_w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}