{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "_tgrLGOCV0wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install configparser langchain google-generativeai chromadb > /dev/null\n",
        "!pip -q install transformers huggingface_hub sentence_transformers > /dev/null"
      ],
      "metadata": {
        "id": "C2mTZv_7g0-i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.environ['API_KEY'])"
      ],
      "metadata": {
        "id": "kbl2u6sG5GxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms.base import LLM\n",
        "from langchain.llms.utils import enforce_stop_tokens\n",
        "from langchain.llms import GooglePalm"
      ],
      "metadata": {
        "id": "U9O9ctkug5PR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Then convert the transformers pipeline into fact_llm \n",
        "\n",
        "fact_llm = GooglePalm(temperature=0.1)"
      ],
      "metadata": {
        "id": "d-blilkQx7yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt_open = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "open_chain = LLMChain(prompt=prompt_open,llm = fact_llm)"
      ],
      "metadata": {
        "id": "fw0ULJdKYc6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
        "\n",
        "print(open_chain.run(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq6do1GvYc2W",
        "outputId": "97e37191-dbbe-4b88-c07e-b966a2a30f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Justin Beiber was born in 1994, so the Super Bowl was in 2015. The team that won the Super Bowl in 2015 was the New England Patriots.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "recurSplitter = RecursiveCharacterTextSplitter(chunk_size=100,\n",
        "                                               chunk_overlap=20,\n",
        "                                               length_function=len)"
      ],
      "metadata": {
        "id": "EE1P3uZ0YcdE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/linux_play.txt') as lin:\n",
        "  txt_lin = lin.read()\n",
        "\n",
        "linux_docs = recurSplitter.create_documents([txt_lin])"
      ],
      "metadata": {
        "id": "dc2UejsER-up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/space_shortened.csv') as spc:\n",
        "  txt_spc = spc.read()\n",
        "\n",
        "space_docs = recurSplitter.create_documents([txt_spc])"
      ],
      "metadata": {
        "id": "Ld9dOjyiR-sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings \n",
        "hfEmbed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "#The all-MiniLM has 384 vector elements. I suspect it may or may not work \n",
        "#with paLM. The alternate will be to work with instructor-xl. Uncomment \n",
        "#below code and execute\n",
        "\n",
        "#hfEmbed = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-xl\")"
      ],
      "metadata": {
        "id": "s8kMbvyDR-nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "space_chroma = Chroma.from_documents(documents=space_docs,\n",
        "                                     embeddings=hfEmbed)"
      ],
      "metadata": {
        "id": "Weno1_dzR-k1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25bd7c33-733e-44a2-d445-4df2313bc8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: space_db\n",
            "WARNING:chromadb.api.models.Collection:No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin_chroma = Chroma.from_documents(documents=linux_docs,\n",
        "                                     embeddings=hfEmbed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM4x9biDR-dE",
        "outputId": "0de16a7b-1474-4eb6-fdfc-6d25af172062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: lin_db\n",
            "WARNING:chromadb.api.models.Collection:No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting the custom tool route"
      ],
      "metadata": {
        "id": "T73D7bKe4FJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_retriever =RetrievalQA.from_chain_type(llm=fact_llm, \n",
        "                                           chain_type=\"stuff\", \n",
        "                                           retriever=lin_chroma.as_retriever())"
      ],
      "metadata": {
        "id": "ESDPHjul3Gi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_retriever(\"What this documents are about?\")"
      ],
      "metadata": {
        "id": "GaEXq4hs74NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space_retriever =RetrievalQA.from_chain_type(llm=fact_llm, \n",
        "                                           chain_type=\"stuff\", \n",
        "                                           retriever=space_chroma.as_retriever())"
      ],
      "metadata": {
        "id": "g52G_gi43ToT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space_retriever(\"how many passengers are there?\")"
      ],
      "metadata": {
        "id": "I1E9JVHD79Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The below code is extending the above retrivers as tools to the agents. Which is not required to execute"
      ],
      "metadata": {
        "id": "PQLU121l8DCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Space Farers\",\n",
        "        func=space_retriever.run,\n",
        "        description=\"useful for when you need to answer questions about the space farers.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Linux Commands\",\n",
        "        func=lin_retriever.run,\n",
        "        description=\"useful for when you need to answer questions about Linux commands.\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "lH_rk4H9286S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_agent = initialize_agent(tools, \n",
        "                         fact_llm, \n",
        "                         agent=\"zero-shot-react-description\", \n",
        "                         verbose=True)"
      ],
      "metadata": {
        "id": "tSJPEXX33uKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_agent.run(\"How many space farers are there?\")"
      ],
      "metadata": {
        "id": "PfaGnNKW3-CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting the custom vectorstore agent route"
      ],
      "metadata": {
        "id": "Rps02Zw84KJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.agent_toolkits import (\n",
        "    create_vectorstore_router_agent,\n",
        "    VectorStoreRouterToolkit,\n",
        "    VectorStoreInfo,\n",
        ")"
      ],
      "metadata": {
        "id": "WGuD67zhWyPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space_vectorstore_info = VectorStoreInfo(\n",
        "    name=\"space\",\n",
        "    description=\"Used when need to answer about Space fares\",\n",
        "    vectorstore=space_chroma\n",
        ")"
      ],
      "metadata": {
        "id": "rzLTa9S3XLIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linux_vectorstore_info = VectorStoreInfo(\n",
        "    name=\"linux\",\n",
        "    description=\"Used when need to answer about playbook\",\n",
        "    vectorstore=lin_chroma\n",
        ")"
      ],
      "metadata": {
        "id": "7JzkHxSLXLFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "router_toolkit = VectorStoreRouterToolkit(\n",
        "    vectorstores=[space_vectorstore_info,\n",
        "                  linux_vectorstore_info],\n",
        "    llm=fact_llm\n",
        ")\n",
        "agent_executor = create_vectorstore_router_agent(\n",
        "    llm=fact_llm,\n",
        "    toolkit=router_toolkit,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "Q9m5ZDcqXLCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"How many Space fares are there?\"\"\""
      ],
      "metadata": {
        "id": "PXqqHJK0YFXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(query)"
      ],
      "metadata": {
        "id": "MWagqEGVXK84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.save_agent(\"multi_doc_agent.json\")"
      ],
      "metadata": {
        "id": "5wCm-r8FWyNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__Z5NKt4WyJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBR74Bl3WyGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PD-9M8VkWyEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xm6ArvS4WyAX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}